import datetime
import json
import os

from . import models

def mine_repo(args):
    extractor = models.GitExtractor()
    git_logs = dict()
    if(args.online):
        try:
            git_logs = extractor.get_online_logs(args.online)
        except FileNotFoundError as ex:
            print(ex)
            git_logs = dict()
    elif(args.local):
        try:
            git_logs = extractor.get_local_logs(args.local)
        except FileNotFoundError as ex:
            print(ex)
            git_logs = dict()

    return git_logs


def manage_cves(args):
    manager = models.CveManager()
    if args.download:
        manager.setup_cves()

    if args.database:
        manager.setup_database()

def get_stats(args, num=None):
    stats = dict()
    if args.online:
        project = get_poject_name(args.online)
    elif args.local:
        project = get_poject_name(args.local)
    # get_stats mines the classified commits using the classes provided
    classifier =  models.CommitClassifier(args.password)
    cve_commits = classifier.get_cve_commits(mine_repo(args))
    # stats are calculated for every cve commit
    for cve in cve_commits:
        stats[cve] = models.CveStatistics(
            project = project,
            active_contributors= cve_commits[cve].contributors,
            active_contributor_count = len(cve_commits[cve].contributors),
            commit_count = cve_commits[cve].between,
            severity = cve_commits[cve].severity,
            base_score = cve_commits[cve].base_score,
            insertions = cve_commits[cve].insertions,
            deletions = cve_commits[cve].deletions,
            files_changed = cve_commits[cve].files_changed,
            found_date = cve_commits[cve].foundCommit['commit_date'],
            fixed_date = cve_commits[cve].fixCommit['commit_date'],
            cwe = cve_commits[cve].cwe,
            language=args.language,
        )
        stats[cve].time_elapsed = models.dateParser(cve_commits[cve].fixCommit['commit_date']) - models.dateParser(cve_commits[cve].foundCommit['commit_date'])
        if models.dateParser(cve_commits[cve].fixCommit['commit_date']) > models.dateParser(str(cve_commits[cve].published_date)):
            stats[cve].from_published = models.dateParser(cve_commits[cve].fixCommit['commit_date']) - models.dateParser(str(cve_commits[cve].published_date))
        else:
            stats[cve].from_published = datetime.timedelta()

    if len(stats) != 0:
        if args.store_db:
            db_manager = models.DatabaseManager(stats, args.apikey)
            #db_manager.insert_db()
            db_manager.insert_mysql()
        global_stats = models.GlobalStatistics(stats)
        global_results = global_stats.calculate_correlation()
        averages = global_stats.calculate_averages()
        stats['correlation_coefficient'] = global_results['corr']
        stats['correlation_from_published_dates'] = global_results['corr_published']
        stats['average_fix_time'] = averages['avg_time']
        stats['average_time_from_published_dates'] = averages['avg_published']
        print('creating stats.json')
        if not num:
            with open('stats.json', 'w', encoding='utf-8') as f:
                json.dump(stats, f, indent=4, cls=models.StatEncoder)
        else:
            with open('stats' + str(num) +'.json', 'w', encoding='utf-8') as f:
                json.dump(stats, f, indent=4, cls=models.StatEncoder)
    else:
        print('No cve-s have been found. No stats.json will be created.')

# reads the json file given in the arguments, it is assumed to be in the dir where the user gives the command
def parse_ghtorrent_json(args):
    class DummyArgs(object):
        def __init__(self, url, password, apikey, store_db, language):
            self.online = url
            self.password = password
            self.apikey = apikey
            self.store_db = store_db
            self.language = language
    # num is a temporary solution to make multi repo stats possbile with a db
    num = 0
    try:
        with open(args.json, 'r', encoding='utf-8') as f:
            repo_list = json.load(f)
    except FileNotFoundError as ex:
        print('The json file was not found')

    for repo in repo_list:
        if 'language' in repo:
            get_stats(DummyArgs(parse_url(repo['url']), args.password, args.apikey, args.store_db, repo['language']), num)
        else:
            get_stats(DummyArgs(parse_url(repo['url']), args.password, args.apikey, args.store_db, args.language), num)
        num = num + 1

# function separated for visibilty
def parse_url(repo_url):
    parts = repo_url.split('/')
    return parts[0] + '//' + parts[2].split('.')[1] + '.' + parts[2].split('.')[2] + '/' + parts[4] + '/' + parts[5]

# simple function to get a projects name
def get_poject_name(url = ''):
    items = url.split('/')
    items.reverse()

    for item in items:
        if item:
            return item
