import subprocess
import os
import json
import re
import numpy
import datetime
import airtable

import gitlogparser.parser as gitParser
import cvemanager.cve_manager as cveManager
import cvemanager.cve_dbms as database

class GitExtractor(object):
    def __init__(self):
        self.logs = list()
        # this is where the repositories will be cloned
        self.repo_path = './repos'
        self.baseDir = os.getcwd()

    def get_online_logs(self, target_url):
        self.download_repo(target_url)
        # prep the directory, since download repo already enters the repo path, it doesn't need to be added
        directory = './' + target_url.split('/')[-1]
        if os.path.isdir(directory):
            return self.get_local_logs(directory)
        else:
            os.chdir(self.baseDir)
            raise FileNotFoundError('The specified directory couldn\'t be downloaded.')

    def get_local_logs(self, target_path):
        # create a dummy class to simulate console argument
        class DummyArgs(object):
            def __init__(self, dir):
                self.directory = dir
        if os.path.isdir(target_path):
            try:
            # parse the git logs
                print('Starting git log parser.')
                gitParser.get_log(DummyArgs(target_path))
            # read the git logs
                if os.path.isfile('logdata_new.json'):
                    with open('logdata_new.json', 'r', encoding='utf-8') as f:
                        self.logs = json.load(f)
            # remove the temporary json file
                    print('Removing temporary json')
                    os.remove('logdata_new.json')
                os.chdir(self.baseDir)
                return self.logs
            except Exception as ex:
                os.chdir(self.baseDir)
                print(ex)

        else:
            raise FileNotFoundError('The specified directory doesn\'t exist!')

    def download_repo(self, target_url):
        # try to open the repo path, if it fails, create a new directory
        try:
            os.chdir(self.repo_path)
        except FileNotFoundError:
            os.mkdir(self.repo_path)
            os.chdir(self.repo_path)

        # clone the requested url
        subprocess.run(['git', 'clone', target_url])


class CveManager(object):
    def __init__(self, password = None):
        self.cve_dir = None
        self.csv_dir = None
        self.user = None
        self.host = None
        self.name = None
        self.owner = None
        self.password = password

    def read_settings(self):
        with open('settings.json', 'r') as f:
            settings = json.load(f)
            self.cve_dir = settings["paths"]["cve_path"]
            self.csv_dir = settings["paths"]["csv_path"]
            self.user = settings['database']['user']
            self.host = settings['database']['host']
            self.name = settings['database']['name']
            self.owner = settings['database']['owner']
            if self.password is None:
                self.password = input('Enter password for %s: ' % settings['database']['user'])

    def setup_cves(self):
        self.read_settings()
        cveManager.download_cves(self.cve_dir, False)
        cveManager.process_cves(self.cve_dir, self.csv_dir, True)

    def setup_database(self):
        self.read_settings()
        database.create_database(self.user, self.password, self.host, self.name, self.owner)
        database.create_tables(self.user, self.password, self.host, self.name)
        database.import_database(self.csv_dir, self.user, self.password, self.host, self.name)

    def get_cve(self, cve_id):
        if self.user is None or self.password is None:
            self.read_settings()
        selected_cve = database.execute_query(self.user, self.password, self.host, self.name, cve_id, date=0)
        if not selected_cve:
            return None
        return selected_cve

    def get_cwe(self, cve_id):
        if self.user is None or self.password is None:
            self.read_settings()
        selected_cwe = database.query_for_cwe(self.user, self.password, self.host, self.name, cve_id)
        if not selected_cwe:
            return None
        return selected_cwe

# class to store data about found cve
class CveData(object):
    def __init__(self, foundCommit = None, fixCommit = None, between = 1, contributors = list(),
     severity = None, base_score=None, published_date=None, files_changed = 0, insertions = 0, deletions = 0, cwe = None):
        self.foundCommit = foundCommit
        self.fixCommit = fixCommit
        self.between = between
        self.contributors = contributors
        self.severity = severity
        self.base_score = base_score
        self.published_date = published_date
        self.insertions = insertions
        self.deletions = deletions
        self.files_changed = files_changed
        self.cwe = cwe

    def __str__(self):
        return f'start commit: {self.foundCommit}, fixing commit: {self.fixCommit}, between them {self.between} commit(s) have been made by {len(self.contributors)} contributors, {self.insertions} lines have been added, {self.deletions} have been deleted and {self.files_changed} files have been changed.'

#class to calssify commits as cve
class CommitClassifier(object):
    def __init__(self, password):
        self.cve_id_pattern = re.compile(r'(cve)\-([0-9]{4})\-(([0-9]{5})|([0-9]{4}))', re.IGNORECASE)
        self.password = password
    # function that gets every commit that looks like a cve and returns it
    def get_cve_commits(self, commits):
        def setup_cve_data(cve):
            cve_commits[cve].contributors.append(commit['author'])
            cve_commits[cve].insertions = cve_commits[cve].foundCommit['insertions']
            cve_commits[cve].deletions = cve_commits[cve].foundCommit['deletions']
            cve_commits[cve].files_changed = cve_commits[cve].foundCommit['files_changed']

        cve_commits = dict()
        cve_manager = CveManager(self.password)
        commits.reverse()
        # look through mined commits and collect every cve
        for commit in commits:
            if commit['message'] and self.cve_id_pattern.search(commit['message']):
                cve = self.cve_id_pattern.search(commit['message']).group(0).upper()
                # get data stored about the cve in the db
                cve_db_data = cve_manager.get_cve(cve)
                if not cve_db_data:
                    continue
                cwe_group = cve_manager.get_cwe(cve)
                # if a cve only appears once it is assumed to be a fix
                # if a cve is not in the database it is considered to be invalid and therefore not considered
                if cve not in cve_commits.keys():
                    cve_commits[cve] = CveData(commit, commit, contributors=list())
                    cve_commits[cve].base_score = cve_db_data[0][5]
                    if cwe_group[0][1]:
                        cve_commits[cve].cwe = cwe_group[0][1]
                    if cve_db_data[0][6]:
                        cve_commits[cve].severity = cve_db_data[0][6].rstrip()
                    elif cve_commits[cve].base_score:
                        if 0 <= cve_commits[cve].base_score < 4:
                            cve_commits[cve].severity = "LOW"
                        elif 4 <= cve_commits[cve].base_score < 7:
                            cve_commits[cve].severity = "MEDIUM"
                        else:
                            cve_commits[cve].severity = "HIGH"
                    else:
                        cve_commits[cve].severity = None
                    cve_commits[cve].published_date = cve_db_data[0][8]
                else:
                    cve_commits[cve].fixCommit = commit
        
        # a for cycle is needed, since I have to recheck every inbetween commit 
        # for their data, since at this point I know when the cve has been fixed
        for cve in cve_commits:
            started = False
            if cve_commits[cve].foundCommit == cve_commits[cve].fixCommit:
                setup_cve_data(cve)
                continue
            else:
                for commit in commits:
                    if started:
                        if commit['author'] not in cve_commits[cve].contributors:
                            cve_commits[cve].contributors.append(commit['author'])
                        
                        cve_commits[cve].between = cve_commits[cve].between + 1
                        cve_commits[cve].insertions = cve_commits[cve].insertions + commit['insertions']
                        cve_commits[cve].deletions = cve_commits[cve].deletions + commit['deletions']
                        cve_commits[cve].files_changed = cve_commits[cve].files_changed + commit['files_changed']

                        
                        if cve_commits[cve].fixCommit == commit:
                            break
                    
                    elif cve_commits[cve].foundCommit == commit:
                        started = True
                        setup_cve_data(cve)

        return cve_commits

# class to store statisctics the have been calculated from CveData objects
class CveStatistics(object):
    def __init__(self, active_contributors = list(), active_contributor_count = 0, commit_count = 0, time_elapsed = None, severity=None, base_score=None, from_published=None, project=None,
        insertions = 0, deletions = 0, files_changed = 0, found_date = None, fixed_date = None, cwe = None):
        self.active_contributors = active_contributors
        self.active_contributor_count = active_contributor_count
        self.commit_count = commit_count
        self.time_elapsed = time_elapsed
        self.severity = severity
        self.base_score = base_score
        self.from_published = from_published
        self.project = project
        self.insertions = insertions
        self.deletions = deletions
        self.files_changed = files_changed
        self.total_lines_changed = insertions + deletions
        self.found_date = found_date
        self.fixed_date = fixed_date
        self.cwe = cwe
    def __str__(self):
        return f'{self.active_contributors}, {self.cwe}, {self.active_contributor_count}, {self.commit_count}, {self.time_elapsed}, {self.severity}, {self.base_score}, {self.published_date}, {self.project}'

    def to_json(self):
        return{
            'project': self.project,
            'active_contributors' : self.active_contributors,
            'active_contributor_count' : self.active_contributor_count,
            'commit_count' : self.commit_count,
            'insertions' : self.insertions,
            'deletions' : self.deletions,
            'total_lines_changed' : self.total_lines_changed,
            'files_changed' : self.files_changed,
            'found_date' : self.found_date,
            'fixed_date' : self.fixed_date,
            'time_elapsed' : str(self.time_elapsed),
            'cwe_group' : self.cwe,
            'severity': self.severity,
            'base_score': self.base_score,
            'from_published': str(self.from_published)
        }

class GlobalStatistics(object):
    def __init__(self, stats=None):
        self.stats = stats
        self.base_scores = list()
        self.contributors = list()
        self.fix_times = list()
        self.fix_times_published = list()
        self.get_stats()

    def get_stats(self):
        for cve in self.stats.keys():
            self.base_scores.append(self.stats[cve].base_score)
            self.contributors.append(self.stats[cve].active_contributor_count)
            self.fix_times.append(self.stats[cve].time_elapsed.total_seconds())
            self.fix_times_published.append(self.stats[cve].from_published.total_seconds())

    def calculate_correlation(self):
        if not self.stats:
            return None

        result = dict()

        corr = numpy.corrcoef(self.base_scores, self.fix_times)
        corr_published = numpy.corrcoef(self.base_scores, self.fix_times_published)

        result['corr'] = corr[0, 1]
        result['corr_published'] = corr_published[0, 1]
        return result

    def calculate_averages(self):
        if not self.stats:
            return None

        result = dict()

        result['avg_time'] = str(datetime.timedelta(seconds=numpy.mean(self.fix_times)))
        result['avg_published'] = str(datetime.timedelta(seconds=numpy.mean(self.fix_times_published)))

        return result


class StatEncoder(json.JSONEncoder):
    def default(self, stats):
        # creates a list out of the mined commits
        if isinstance(stats, CveStatistics):
            return stats.to_json()
        return super(StatEncoder, self).default(stats)

class DatabaseManager(object):
    def __init__(self, stats, apikey):
        self.stats = stats
        self.apikey = apikey

    def insert_db(self):
        if self.apikey is None:
            self.apikey = input('Enter api key: ')

        print("Uploading to Airtable")

        new_entries = False
        cve_table = airtable.Airtable('appX3T3GA3Tim89PA', 'cve_data', api_key=self.apikey)
        contributor_table = airtable.Airtable('appX3T3GA3Tim89PA', 'contributors', api_key=self.apikey)
        contributed_table = airtable.Airtable('appX3T3GA3Tim89PA', 'contributed', api_key=self.apikey)
        for cve in self.stats.keys():
            existing_records = cve_table.search('cve_key', self.stats[cve].project + '-' + cve)

            if len(existing_records) is 0:
                new_entries = True
                record = {
                    'cve_id': cve,
                    'project': self.stats[cve].project,
                    'cwe_group': self.stats[cve].cwe,
                    'active_contributor_count': self.stats[cve].active_contributor_count,
                    'commit_count': self.stats[cve].commit_count,
                    'time_elapsed': str(self.stats[cve].time_elapsed),
                    'severity': self.stats[cve].severity,
                    'base_score': self.stats[cve].base_score,
                    'from_published': str(self.stats[cve].from_published)
                }
                cve_table.insert(record)

            for contributor in self.stats[cve].active_contributors:
                existing_records = contributor_table.search('email', contributor['email'])

                if len(existing_records) is 0:
                    record = {
                        'email': contributor['email'],
                        'name': contributor['name']
                    }
                    contributor_table.insert(record)

                existing_records = contributed_table.search('contributed_id', self.stats[cve].project + '-' + cve + ':' + contributor['email'])
                if len(existing_records) is 0:
                    record = {
                        'cve_key': self.stats[cve].project + '-' + cve,
                        'contributor_email': contributor['email']
                    }
                    contributed_table.insert(record)

        if new_entries:
            self.calculate_stats(cve_table)


    def calculate_stats(self, table):
        stats_table = airtable.Airtable('appX3T3GA3Tim89PA', 'stats', api_key=self.apikey)

        tm = TimeManager()
        stats = dict()
        cves = table.get_all(fields=['cve_id', 'active_contributor_count', 'time_elapsed', 'base_score', 'from_published'])
        for record in cves:
            cve = record['fields']['cve_id']
            stats[cve] = CveStatistics()
            stats[cve].active_contributors = record['fields']['active_contributor_count']
            stats[cve].time_elapsed = tm.to_timedelta(record['fields']['time_elapsed'])
            stats[cve].base_score = record['fields']['base_score']
            stats[cve].from_published = tm.to_timedelta(record['fields']['from_published'])

        gs = GlobalStatistics(stats)
        cors = gs.calculate_correlation()
        avgs = gs.calculate_averages()

        stat_record = stats_table.match('type', 'correlation_coefficient')
        stats_table.update(stat_record['id'], {'value': str(cors['corr'])})
        stat_record = stats_table.match('type', 'correlation_from_published_dates')
        stats_table.update(stat_record['id'], {'value': str(cors['corr_published'])})
        stat_record = stats_table.match('type', 'average_fix_time')
        stats_table.update(stat_record['id'], {'value': str(avgs['avg_time'])})
        stat_record = stats_table.match('type', 'average_from_published_dates')
        stats_table.update(stat_record['id'], {'value': str(avgs['avg_published'])})


class TimeManager(object):
    def __init__(self):
        pass

    def to_timedelta(self, date_string):
        days = ''
        timestamp = ''
        if date_string.find('days') != -1:
            days, timestamp = date_string.split(" days, ")
        else:
            timestamp = date_string

        t = datetime.datetime.strptime(timestamp, "%H:%M:%S")
        if days:
            return datetime.timedelta(days=int(days), hours=t.hour, minutes=t.minute, seconds=t.second)

        return datetime.timedelta(hours=t.hour, minutes=t.minute, seconds=t.second)
