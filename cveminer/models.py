import subprocess
import os
import json
import re
import numpy
import datetime
import airtable

import gitlogparser.parser as gitParser
import cvemanager.cve_manager as cveManager
import cvemanager.cve_dbms as database

class GitExtractor(object):
    def __init__(self):
        self.logs = list()
        # this is where the repositories will be cloned
        self.repo_path = './repos'
        self.baseDir = os.getcwd()

    def get_online_logs(self, target_url):
        self.download_repo(target_url)
        # prep the directory, since download repo already enters the repo path, it doesn't need to be added
        directory = './' + target_url.split('/')[-1]
        if os.path.isdir(directory):
            return self.get_local_logs(directory)
        else:
            os.chdir(self.baseDir)
            raise FileNotFoundError('The specified directory couldn\'t be downloaded.')

    def get_local_logs(self, target_path):
        # create a dummy class to simulate console argument
        class DummyArgs(object):
            def __init__(self, dir):
                self.directory = dir
        if os.path.isdir(target_path):
            try:
            # parse the git logs
                print('Starting git log parser.')
                gitParser.get_log(DummyArgs(target_path))
            # read the git logs
                if os.path.isfile('logdata_new.json'):
                    with open('logdata_new.json', 'r', encoding='utf-8') as f:
                        self.logs = json.load(f)
            # remove the temporary json file
                    print('Removing temporary json')
                    os.remove('logdata_new.json')
                os.chdir(self.baseDir)
                return self.logs
            except Exception as ex:
                os.chdir(self.baseDir)
                print(ex)

        else:
            raise FileNotFoundError('The specified directory doesn\'t exist!')

    def download_repo(self, target_url):
        # try to open the repo path, if it fails, create a new directory
        try:
            os.chdir(self.repo_path)
        except FileNotFoundError:
            os.mkdir(self.repo_path)
            os.chdir(self.repo_path)

        # clone the requested url
        subprocess.run(['git', 'clone', target_url])


class CveManager(object):
    def __init__(self, password = None):
        self.cve_dir = None
        self.csv_dir = None
        self.user = None
        self.host = None
        self.name = None
        self.owner = None
        self.password = password

    def read_settings(self):
        with open('settings.json', 'r') as f:
            settings = json.load(f)
            self.cve_dir = settings["paths"]["cve_path"]
            self.csv_dir = settings["paths"]["csv_path"]
            self.user = settings['database']['user']
            self.host = settings['database']['host']
            self.name = settings['database']['name']
            self.owner = settings['database']['owner']
            if self.password is None:
                self.password = input('Enter password for %s: ' % settings['database']['user'])

    def setup_cves(self):
        self.read_settings()
        cveManager.download_cves(self.cve_dir, False)
        cveManager.process_cves(self.cve_dir, self.csv_dir, True)

    def setup_database(self):
        self.read_settings()
        database.create_database(self.user, self.password, self.host, self.name, self.owner)
        database.create_tables(self.user, self.password, self.host, self.name)
        database.import_database(self.csv_dir, self.user, self.password, self.host, self.name)

    def get_cve(self, cve_id):
        if self.user is None or self.password is None:
            self.read_settings()
        selected_cve = database.execute_query(self.user, self.password, self.host, self.name, cve_id, date=0)
        if not selected_cve:
            return None
        return selected_cve

# class to store data about found cve
class CveData(object):
    def __init__(self, foundCommit = None, fixCommit = None, between = 0, contributors = list(), severity = None, base_score=None, published_date=None):
        self.foundCommit = foundCommit
        self.fixCommit = fixCommit
        self.between = between
        self.contributors = contributors
        self.severity = severity
        self.base_score = base_score
        self.published_date = published_date

    def __str__(self):
        return f'start commit: {self.foundCommit}, fixing commit: {self.fixCommit}, between them {self.between} commit(s) have been made by {len(self.contributors)} contributors'

#class to calssify commits as cve
class CommitClassifier(object):
    def __init__(self, password):
        self.cve_id_pattern = re.compile(r'(cve)\-([0-9]{4})\-(([0-9]{5})|([0-9]{4}))', re.IGNORECASE)
        self.password = password
    # function that gets every commit that looks like a cve and returns it
    def get_cve_commits(self, commits):
        cve_commits = dict()
        cve_manager = CveManager(self.password)
        commits.reverse()
        # look through mined commits and collect every cve
        for commit in commits:
            if commit['message'] and self.cve_id_pattern.search(commit['message']):
                cve = self.cve_id_pattern.search(commit['message']).group(0).upper()
                # get data stored about the cve in the db
                cve_db_data = cve_manager.get_cve(cve)
                # if a cve only appears once it is assumed to be a fix
                # if a cve is not in the database it is considered to be invalid and therefore not considered
                if cve not in cve_commits.keys() and cve_db_data:
                    cve_commits[cve] = CveData(commit, commit, contributors=list())
                    cve_commits[cve].base_score = cve_db_data[0][5]
                    if cve_db_data[0][6]:
                        cve_commits[cve].severity = cve_db_data[0][6].rstrip()
                    elif cve_commits[cve].base_score:
                        if 0 <= cve_commits[cve].base_score < 4:
                            cve_commits[cve].severity = "LOW"
                        elif 4 <= cve_commits[cve].base_score < 7:
                            cve_commits[cve].severity = "MEDIUM"
                        else:
                            cve_commits[cve].severity = "HIGH"
                    else:
                        cve_commits[cve].severity = None
                    cve_commits[cve].published_date = cve_db_data[0][8]
                else:
                    cve_commits[cve].fixCommit = commit
        
        # a for cycle is needed, since I have to recheck every inbetween commit 
        # for their data, since at this point I know when the cve has been fixed
        for cve in cve_commits:
            started = False
            if cve_commits[cve].foundCommit == cve_commits[cve].fixCommit:
                cve_commits[cve].contributors.append(commit['author'])
                continue
            else:
                for commit in commits:
                    if started:
                        if commit['author'] not in cve_commits[cve].contributors:
                            cve_commits[cve].contributors.append(commit['author'])
                        
                        cve_commits[cve].between = cve_commits[cve].between + 1
                        
                        if cve_commits[cve].fixCommit == commit:
                            break
                    
                    elif cve_commits[cve].foundCommit == commit:
                        started = True
                        cve_commits[cve].contributors.append(commit['author'])

        return cve_commits

# class to store statisctics the have been calculated from CveData objects
class CveStatistics(object):
    def __init__(self, active_contributors = list(), active_contributor_count = 0, commit_count = 0, time_elapsed = None, severity=None, base_score=None, published_date=None, project=None):
        self.active_contributors = active_contributors
        self.active_contributor_count = active_contributor_count
        self.commit_count = commit_count
        self.time_elapsed = time_elapsed
        self.severity = severity
        self.base_score = base_score
        self.published_date = published_date
        self.project = project

    def __str__(self):
        return f'{self.active_contributors}, {self.active_contributor_count}, {self.commit_count}, {self.time_elapsed}, {self.severity}, {self.base_score}'

    def to_json(self):
        return{
            'project': self.project,
            'active_contributors' : self.active_contributors,
            'active_contributor_count' : self.active_contributor_count,
            'commit_count' : self.commit_count,
            'time_elapsed' : str(self.time_elapsed),
            'severity': self.severity,
            'base_score': self.base_score,
            'from_published': str(self.published_date)
        }

class GlobalStatistics(object):
    def __init__(self, stats=None):
        self.stats = stats
        self.base_scores = list()
        self.contributors = list()
        self.fix_times = list()
        self.fix_times_published = list()

    def get_stats(self):
        for cve in self.stats.keys():
            self.base_scores.append(self.stats[cve].base_score)
            self.contributors.append(self.stats[cve].active_contributor_count)
            self.fix_times.append(self.stats[cve].time_elapsed.total_seconds())
            self.fix_times_published.append(self.stats[cve].published_date.total_seconds())

    def calculate_correlation(self):
        if not self.stats:
            return None

        result = dict()

        corr = numpy.corrcoef(self.base_scores, self.fix_times)
        corr_published = numpy.corrcoef(self.base_scores, self.fix_times_published)

        result['corr'] = corr[0, 1]
        result['corr_published'] = corr_published[0, 1]
        return result

    def calculate_averages(self):
        if not self.stats:
            return None

        result = dict()

        result['avg_time'] = str(datetime.timedelta(seconds=numpy.mean(self.fix_times)))
        result['avg_published'] = str(datetime.timedelta(seconds=numpy.mean(self.fix_times_published)))

        return result


class StatEncoder(json.JSONEncoder):
    def default(self, stats):
        # creates a list out of the mined commits
        if isinstance(stats, CveStatistics):
            return stats.to_json()
        return super(StatEncoder, self).default(stats)

class DatabaseManager(object):
    def __init__(self, stats, apikey):
        self.stats = stats
        self.apikey = apikey

    def insert_db(self):
        if self.apikey is None:
            self.apikey = input('Enter api key: ')

        cve_table = airtable.Airtable('appX3T3GA3Tim89PA', 'cve_data', api_key=self.apikey)
        contributor_table = airtable.Airtable('appX3T3GA3Tim89PA', 'contributors', api_key=self.apikey)
        contributed_table = airtable.Airtable('appX3T3GA3Tim89PA', 'contributed', api_key=self.apikey)
        for cve in self.stats.keys():
            existing_records = cve_table.search('cve_key', self.stats[cve].project + '-' + cve)

            if len(existing_records) is 0:
                record = {
                    'cve_id': cve,
                    'project': self.stats[cve].project,
                    'active_contributor_count': self.stats[cve].active_contributor_count,
                    'commit_count': self.stats[cve].commit_count,
                    'time_elapsed': str(self.stats[cve].time_elapsed),
                    'severity': self.stats[cve].severity,
                    'base_score': self.stats[cve].base_score,
                    'from_published': str(self.stats[cve].published_date)
                }
                cve_table.insert(record)

            for contributor in self.stats[cve].active_contributors:
                existing_records = contributor_table.search('email', contributor['email'])

                if len(existing_records) is 0:
                    record = {
                        'email': contributor['email'],
                        'name': contributor['name']
                    }
                    contributor_table.insert(record)

                existing_records = contributed_table.search('contributed_id', self.stats[cve].project + '-' + cve + ':' + contributor['email'])
                if len(existing_records) is 0:
                    record = {
                        'cve_key': self.stats[cve].project + '-' + cve,
                        'contributor_email': contributor['email']
                    }
                    contributed_table.insert(record)
